# ä¼˜åŒ– YOLOv5 çš„è¶…å‚æ•°è¿›åŒ–æŒ‡å—

ğŸ“š æœ¬æŒ‡å—è§£é‡Šäº†å¦‚ä½•ä¸º YOLOv5 ğŸš€ è¿›è¡Œ **è¶…å‚æ•°è¿›åŒ–**ã€‚è¶…å‚æ•°è¿›åŒ–æ˜¯ä½¿ç”¨ [é—ä¼ ç®—æ³• (GA)](https://en.wikipedia.org/wiki/Genetic_algorithm) è¿›è¡Œ [è¶…å‚æ•°ä¼˜åŒ–](https://en.wikipedia.org/wiki/Hyperparameter_optimization) çš„æ–¹æ³•ã€‚

æœºå™¨å­¦ä¹ ä¸­çš„è¶…å‚æ•°æ§åˆ¶è®­ç»ƒçš„å„ä¸ªæ–¹é¢ï¼Œæ‰¾åˆ°å®ƒä»¬çš„æœ€ä½³å€¼å¯èƒ½æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•å¦‚ç½‘æ ¼æœç´¢åœ¨é¢å¯¹é«˜ç»´æœç´¢ç©ºé—´ã€ä¸æ˜ç»´åº¦é—´çš„ç›¸å…³æ€§ä»¥åŠæ¯ä¸ªç‚¹çš„æ˜‚è´µè¯„ä¼°æ—¶ï¼Œä¼šå˜å¾—ä¸å¯è¡Œï¼Œå› æ­¤ GA æˆä¸ºè¶…å‚æ•°æœç´¢çš„åˆé€‚é€‰æ‹©ã€‚

## åœ¨å¼€å§‹ä¹‹å‰

åœ¨ [**Python>=3.8.0**](https://www.python.org/) ç¯å¢ƒä¸­å…‹éš†ä»£ç åº“å¹¶å®‰è£… [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt)ï¼ŒåŒ…æ‹¬ [**PyTorch>=1.8**](https://pytorch.org/get-started/locally/)ã€‚[æ¨¡å‹](https://github.com/ultralytics/yolov5/tree/master/models) å’Œ [æ•°æ®é›†](https://github.com/ultralytics/yolov5/tree/master/data) ä¼šä»æœ€æ–°çš„ YOLOv5 [å‘å¸ƒ](https://github.com/ultralytics/yolov5/releases) ä¸­è‡ªåŠ¨ä¸‹è½½ã€‚

```bash
git clone https://github.com/ultralytics/yolov5  # å…‹éš†ä»“åº“
cd yolov5
pip install -r requirements.txt  # å®‰è£…ä¾èµ–
```

## 1. Initialize Hyperparameters
1. åˆå§‹åŒ–è¶…å‚æ•°
YOLOv5 æœ‰å¤§çº¦ 30 ä¸ªè¶…å‚æ•°ç”¨äºå„ç§è®­ç»ƒè®¾ç½®ã€‚è¿™äº›å®šä¹‰åœ¨ /data/hyps ç›®å½•ä¸‹çš„ *.yaml æ–‡ä»¶ä¸­ã€‚æ›´å¥½çš„åˆå§‹çŒœæµ‹ä¼šäº§ç”Ÿæ›´å¥½çš„æœ€ç»ˆç»“æœï¼Œå› æ­¤åœ¨è¿›åŒ–ä¹‹å‰æ­£ç¡®åˆå§‹åŒ–è¿™äº›å€¼éå¸¸é‡è¦ã€‚å¦‚æœä¸ç¡®å®šï¼Œè¯·ä½¿ç”¨é»˜è®¤å€¼ï¼Œè¿™äº›å€¼æ˜¯ä¸ºä»å¤´å¼€å§‹è®­ç»ƒ YOLOv5 COCO ä¼˜åŒ–çš„ã€‚
YOLOv5 has about 30 hyperparameters used for various training settings. These are defined in `*.yaml` files in the `/data/hyps` directory. Better initial guesses will produce better final results, so it is important to initialize these values properly before evolving. If in doubt, simply use the default values, which are optimized for YOLOv5 COCO training from scratch.

```yaml
# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
# è¶…å‚æ•°ç”¨äºä»å¤´å¼€å§‹ä½å¢å¼º COCO è®­ç»ƒ
# python train.py --batch 64 --cfg yolov5n6.yaml --weights '' --data coco.yaml --img 640 --epochs 300 --linear
# æœ‰å…³è¶…å‚æ•°è¿›åŒ–çš„æ•™ç¨‹ï¼Œè¯·å‚è§ https://github.com/ultralytics/yolov5#tutorials

lr0: 0.01  # åˆå§‹å­¦ä¹ ç‡ (SGD=1E-2, Adam=1E-3)
lrf: 0.01  # æœ€ç»ˆ OneCycleLR å­¦ä¹ ç‡ (lr0 * lrf)
momentum: 0.937  # SGD åŠ¨é‡/Adam beta1
weight_decay: 0.0005  # ä¼˜åŒ–å™¨æƒé‡è¡°å‡ 5e-4
warmup_epochs: 3.0  # é¢„çƒ­ epochï¼ˆåˆ†æ•°ä¹Ÿå¯ä»¥ï¼‰
warmup_momentum: 0.8  # é¢„çƒ­åˆå§‹åŠ¨é‡
warmup_bias_lr: 0.1  # é¢„çƒ­åˆå§‹åç½® lr
box: 0.05  # è¾¹æ¡†æŸå¤±å¢ç›Š
cls: 0.5  # ç±»åˆ«æŸå¤±å¢ç›Š
cls_pw: 1.0  # ç±»åˆ« BCELoss æ­£æƒé‡
obj: 1.0  # å¯¹è±¡æŸå¤±å¢ç›Šï¼ˆéšåƒç´ ç¼©æ”¾ï¼‰
obj_pw: 1.0  # å¯¹è±¡ BCELoss æ­£æƒé‡
iou_t: 0.20  # IoU è®­ç»ƒé˜ˆå€¼
anchor_t: 4.0  # é”šå®šå¤šé‡é˜ˆå€¼
# anchors: 3  # æ¯ä¸ªè¾“å‡ºå±‚çš„é”šç‚¹ï¼ˆ0 è¡¨ç¤ºå¿½ç•¥ï¼‰
fl_gamma: 0.0  # ç„¦ç‚¹æŸå¤± gamma (efficientDet é»˜è®¤ gamma=1.5)
hsv_h: 0.015  # å›¾åƒ HSV-Hue å¢å¼ºï¼ˆåˆ†æ•°ï¼‰
hsv_s: 0.7  # å›¾åƒ HSV-Saturation å¢å¼ºï¼ˆåˆ†æ•°ï¼‰
hsv_v: 0.4  # å›¾åƒ HSV-Value å¢å¼ºï¼ˆåˆ†æ•°ï¼‰
degrees: 0.0  # å›¾åƒæ—‹è½¬ï¼ˆ+/- åº¦ï¼‰
translate: 0.1  # å›¾åƒå¹³ç§»ï¼ˆ+/- åˆ†æ•°ï¼‰
scale: 0.5  # å›¾åƒç¼©æ”¾ï¼ˆ+/- å¢ç›Šï¼‰
shear: 0.0  # å›¾åƒå‰ªåˆ‡ï¼ˆ+/- åº¦ï¼‰
perspective: 0.0  # å›¾åƒé€è§†ï¼ˆ+/- åˆ†æ•°ï¼‰ï¼ŒèŒƒå›´ 0-0.001
flipud: 0.0  # å›¾åƒä¸Šä¸‹ç¿»è½¬ï¼ˆæ¦‚ç‡ï¼‰
fliplr: 0.5  # å›¾åƒå·¦å³ç¿»è½¬ï¼ˆæ¦‚ç‡ï¼‰
mosaic: 1.0  # å›¾åƒé©¬èµ›å…‹ï¼ˆæ¦‚ç‡ï¼‰
mixup: 0.0  # å›¾åƒæ··åˆï¼ˆæ¦‚ç‡ï¼‰
copy_paste: 0.0  # æ®µè½å¤åˆ¶ç²˜è´´ï¼ˆæ¦‚ç‡ï¼‰

```

## 2. Define Fitness
2. å®šä¹‰é€‚åº”åº¦
é€‚åº”åº¦æ˜¯æˆ‘ä»¬è¦æœ€å¤§åŒ–çš„å€¼ã€‚åœ¨ YOLOv5 ä¸­ï¼Œæˆ‘ä»¬å°†é»˜è®¤é€‚åº”åº¦å‡½æ•°å®šä¹‰ä¸ºæŒ‡æ ‡çš„åŠ æƒç»„åˆï¼šmAP@0.5 å æƒé‡çš„ 10%ï¼ŒmAP@0.5:0.95 å å‰©ä½™çš„ 90%ï¼Œä¸åŒ…æ‹¬ ç²¾åº¦ P å’Œå¬å›ç‡ Rã€‚ä½ å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´è¿™äº›ï¼Œæˆ–è€…ä½¿ç”¨ utils/metrics.py ä¸­çš„é»˜è®¤é€‚åº”åº¦å®šä¹‰ï¼ˆæ¨èï¼‰ã€‚
Fitness is the value we seek to maximize. In YOLOv5 we define a default fitness function as a weighted combination of metrics: `mAP@0.5` contributes 10% of the weight and `mAP@0.5:0.95` contributes the remaining 90%, with [Precision `P` and Recall `R`](https://en.wikipedia.org/wiki/Precision_and_recall) absent. You may adjust these as you see fit or use the default fitness definition in utils/metrics.py (recommended).

```python
def fitness(x):
    """é€šè¿‡å¯¹åŠ æƒæŒ‡æ ‡ [P, R, mAP@0.5, mAP@0.5:0.95] æ±‚å’Œæ¥è¯„ä¼°æ¨¡å‹çš„é€‚åº”åº¦ï¼Œx æ˜¯å½¢çŠ¶ä¸º (n, 4) çš„ numpy æ•°ç»„ã€‚"""
    w = [0.0, 0.0, 0.1, 0.9]  # [P, R, mAP@0.5, mAP@0.5:0.95] çš„æƒé‡
    return (x[:, :4] * w).sum(1)
```

## 3. Evolve
3. è¿›åŒ–
è¿›åŒ–æ˜¯åœ¨æˆ‘ä»¬æƒ³è¦æ”¹è¿›çš„åŸºæœ¬æƒ…æ™¯ä¸‹è¿›è¡Œçš„ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼ŒåŸºæœ¬æƒ…æ™¯æ˜¯ä½¿ç”¨é¢„è®­ç»ƒçš„ YOLOv5s å¯¹ COCO128 è¿›è¡Œ 10 è½®å¾®è°ƒã€‚åŸºæœ¬æƒ…æ™¯çš„è®­ç»ƒå‘½ä»¤æ˜¯ï¼š
Evolution is performed about a base scenario which we seek to improve upon. The base scenario in this example is finetuning COCO128 for 10 epochs using pretrained YOLOv5s. The base scenario training command is:

```bash
python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache
```
è¦ é’ˆå¯¹è¯¥æƒ…æ™¯ è¿›è¡Œè¶…å‚æ•°è¿›åŒ–ï¼Œä» ç¬¬ 1 éƒ¨åˆ† ä¸­å®šä¹‰çš„åˆå§‹å€¼å¼€å§‹ï¼Œå¹¶æœ€å¤§åŒ– ç¬¬ 2 éƒ¨åˆ† ä¸­å®šä¹‰çš„é€‚åº”åº¦ï¼Œè¯·æ·»åŠ  --evolveï¼š
To evolve hyperparameters **specific to this scenario**, starting from our initial values defined in **Section 1.**, and maximizing the fitness defined in **Section 2.**, append `--evolve`:

```bash
# å• GPU
python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache --evolve

# å¤š GPU
for i in 0 1 2 3 4 5 6 7; do
  sleep $(expr 30 \* $i) &&  # 30 ç§’å»¶è¿Ÿï¼ˆå¯é€‰ï¼‰
  echo 'Starting GPU '$i'...' &&
  nohup python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache --device $i --evolve > evolve_gpu_$i.log &
done

# å¤š GPU bash-whileï¼ˆä¸æ¨èï¼‰
for i in 0 1 2 3 4 5 6 7; do
  sleep $(expr 30 \* $i) &&  # 30 ç§’å»¶è¿Ÿï¼ˆå¯é€‰ï¼‰
  echo 'Starting GPU '$i'...' &&
  "$(while true; do nohup python train.py... --device $i --evolve 1 > evolve_gpu_$i.log; done)" &
done

```
é»˜è®¤çš„è¿›åŒ–è®¾ç½®å°†è¿è¡ŒåŸºæœ¬æƒ…æ™¯ 300 æ¬¡ï¼Œå³ 300 ä»£ã€‚ä½ å¯ä»¥é€šè¿‡ --evolve å‚æ•°ä¿®æ”¹ä»£æ•°ï¼Œå³ python train.py --evolve 1000ã€‚
The default evolution settings will run the base scenario 300 times, i.e. for 300 generations. You can modify generations via the `--evolve` argument, i.e. `python train.py --evolve 1000`.

ä¸»è¦çš„é—ä¼ æ“ä½œæ˜¯ äº¤å‰ å’Œ å˜å¼‚ã€‚åœ¨æ­¤å·¥ä½œä¸­ä½¿ç”¨å˜å¼‚ï¼Œä»¥ 80% çš„æ¦‚ç‡å’Œ 0.04 çš„æ–¹å·®åŸºäºä¹‹å‰æ‰€æœ‰ä»£ä¸­æœ€ä½³çˆ¶ä»£çš„ç»„åˆåˆ›å»ºæ–°åä»£ã€‚ç»“æœè®°å½•åœ¨ runs/evolve/exp/evolve.csvï¼Œå¹¶åœ¨æ¯ä¸€ä»£ä¸­ä¿å­˜æœ€é«˜é€‚åº”åº¦çš„åä»£ä¸º runs/evolve/hyp_evolved.yamlï¼š
The main genetic operators are **crossover** and **mutation**. In this work mutation is used, with an 80% probability and a 0.04 variance to create new offspring based on a combination of the best parents from all previous generations. Results are logged to `runs/evolve/exp/evolve.csv`, and the highest fitness offspring is saved every generation as `runs/evolve/hyp_evolved.yaml`:

```yaml
# YOLOv5 Hyperparameter Evolution Results
# Best generation: 287
# Last generation: 300
#    metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss
#              0.54634,              0.55625,              0.58201,              0.33665,             0.056451,             0.042892,             0.013441

# YOLOv5 è¶…å‚æ•°è¿›åŒ–ç»“æœ
# æœ€ä½³ä»£æ•°: 287
# æœ€åä»£æ•°: 300
#    æŒ‡æ ‡/ç²¾åº¦,       æŒ‡æ ‡/å¬å›ç‡,      æŒ‡æ ‡/mAP_0.5, æŒ‡æ ‡/mAP_0.5:0.95,         éªŒè¯/æ¡†æŸå¤±,         éªŒè¯/ç›®æ ‡æŸå¤±,         éªŒè¯/åˆ†ç±»æŸå¤±
#              0.54634,              0.55625,              0.58201,              0.33665,             0.056451,             0.042892,             0.013441

lr0: 0.01  # åˆå§‹å­¦ä¹ ç‡ (SGD=1E-2, Adam=1E-3)
lrf: 0.2  # æœ€ç»ˆOneCycleLRå­¦ä¹ ç‡ (lr0 * lrf)
momentum: 0.937  # SGDåŠ¨é‡/Adam beta1
weight_decay: 0.0005  # ä¼˜åŒ–å™¨æƒé‡è¡°å‡ 5e-4
warmup_epochs: 3.0  # é¢„çƒ­ä¸–ä»£ï¼ˆå¯ä»¥æ˜¯å°æ•°ï¼‰
warmup_momentum: 0.8  # é¢„çƒ­åˆå§‹åŠ¨é‡
warmup_bias_lr: 0.1  # é¢„çƒ­åˆå§‹åç½®å­¦ä¹ ç‡
box: 0.05  # æ¡†æŸå¤±å¢ç›Š
cls: 0.5  # åˆ†ç±»æŸå¤±å¢ç›Š
cls_pw: 1.0  # åˆ†ç±»BCELossæ­£æƒé‡
obj: 1.0  # ç›®æ ‡æŸå¤±å¢ç›Šï¼ˆéšåƒç´ ç¼©æ”¾ï¼‰
obj_pw: 1.0  # ç›®æ ‡BCELossæ­£æƒé‡
iou_t: 0.20  # è®­ç»ƒIoUé˜ˆå€¼
anchor_t: 4.0  # é”šç‚¹å¤šé‡é˜ˆå€¼
# anchors: 3  # æ¯ä¸ªè¾“å‡ºå±‚çš„é”šç‚¹ï¼ˆ0è¡¨ç¤ºå¿½ç•¥ï¼‰
fl_gamma: 0.0  # focalæŸå¤±gammaï¼ˆefficientDeté»˜è®¤gamma=1.5ï¼‰
hsv_h: 0.015  # å›¾åƒHSV-è‰²è°ƒå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
hsv_s: 0.7  # å›¾åƒHSV-é¥±å’Œåº¦å¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
hsv_v: 0.4  # å›¾åƒHSV-æ˜åº¦å¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
degrees: 0.0  # å›¾åƒæ—‹è½¬ï¼ˆæ­£è´Ÿåº¦ï¼‰
translate: 0.1  # å›¾åƒå¹³ç§»ï¼ˆæ­£è´Ÿæ¯”ä¾‹ï¼‰
scale: 0.5  # å›¾åƒç¼©æ”¾ï¼ˆæ­£è´Ÿå¢ç›Šï¼‰
shear: 0.0  # å›¾åƒå‰ªåˆ‡ï¼ˆæ­£è´Ÿåº¦ï¼‰
perspective: 0.0  # å›¾åƒé€è§†ï¼ˆæ­£è´Ÿæ¯”ä¾‹ï¼‰ï¼ŒèŒƒå›´0-0.001
flipud: 0.0  # å›¾åƒä¸Šä¸‹ç¿»è½¬ï¼ˆæ¦‚ç‡ï¼‰
fliplr: 0.5  # å›¾åƒå·¦å³ç¿»è½¬ï¼ˆæ¦‚ç‡ï¼‰
mosaic: 1.0  # å›¾åƒæ‹¼æ¥ï¼ˆæ¦‚ç‡ï¼‰
mixup: 0.0  # å›¾åƒæ··åˆï¼ˆæ¦‚ç‡ï¼‰
copy_paste: 0.0  # åˆ†æ®µå¤åˆ¶ç²˜è´´ï¼ˆæ¦‚ç‡ï¼‰

```
æˆ‘ä»¬å»ºè®®è¿›è¡Œè‡³å°‘300ä»£çš„è¿›åŒ–ä»¥è·å¾—æœ€ä½³ç»“æœã€‚è¯·æ³¨æ„ï¼Œè¿›åŒ–é€šå¸¸æ˜¯æ˜‚è´µä¸”è€—æ—¶çš„ï¼Œå› ä¸ºåŸºæœ¬åœºæ™¯éœ€è¦è®­ç»ƒæ•°ç™¾æ¬¡ï¼Œå¯èƒ½éœ€è¦æ•°ç™¾ç”šè‡³æ•°åƒä¸ªGPUå°æ—¶ã€‚
We recommend a minimum of 300 generations of evolution for best results. Note that **evolution is generally expensive and time-consuming**, as the base scenario is trained hundreds of times, possibly requiring hundreds or thousands of GPU hours.

## 4. Visualize
4. å¯è§†åŒ–
evolve.csvåœ¨è¿›åŒ–ç»“æŸåç”±utils.plots.plot_evolve()ç»˜åˆ¶ä¸ºevolve.pngï¼Œæ¯ä¸ªè¶…å‚æ•°ä¸€ä¸ªå­å›¾ï¼Œæ˜¾ç¤ºé€‚åº”åº¦ï¼ˆyè½´ï¼‰ä¸è¶…å‚æ•°å€¼ï¼ˆxè½´ï¼‰çš„å…³ç³»ã€‚é»„è‰²è¡¨ç¤ºè¾ƒé«˜æµ“åº¦ã€‚å‚ç›´åˆ†å¸ƒè¡¨ç¤ºä¸€ä¸ªå‚æ•°å·²ç¦ç”¨ä¸”ä¸å˜å¼‚ã€‚è¿™åœ¨train.pyä¸­çš„metaå­—å…¸ä¸­å¯ç”±ç”¨æˆ·é€‰æ‹©ï¼Œé€‚ç”¨äºå›ºå®šå‚æ•°å¹¶é˜²æ­¢å®ƒä»¬è¿›åŒ–ã€‚
`evolve.csv` is plotted as `evolve.png` by `utils.plots.plot_evolve()` after evolution finishes with one subplot per hyperparameter showing fitness (y-axis) vs hyperparameter values (x-axis). Yellow indicates higher concentrations. Vertical distributions indicate that a parameter has been disabled and does not mutate. This is user selectable in the `meta` dictionary in train.py, and is useful for fixing parameters and preventing them from evolving.

![evolve](https://user-images.githubusercontent.com/26833433/89130469-f43e8e00-d4b9-11ea-9e28-f8ae3622516d.png)

## Supported Environments

Ultralytics provides a range of ready-to-use environments, each pre-installed with essential dependencies such as [CUDA](https://developer.nvidia.com/cuda), [CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/), and [PyTorch](https://pytorch.org/), to kickstart your projects.

- **Free GPU Notebooks**: <a href="https://bit.ly/yolov5-paperspace-notebook"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Run on Gradient"></a> <a href="https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> <a href="https://www.kaggle.com/ultralytics/yolov5"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a>
- **Google Cloud**: [GCP Quickstart Guide](../environments/google_cloud_quickstart_tutorial.md)
- **Amazon**: [AWS Quickstart Guide](../environments/aws_quickstart_tutorial.md)
- **Azure**: [AzureML Quickstart Guide](../environments/azureml_quickstart_tutorial.md)
- **Docker**: [Docker Quickstart Guide](../environments/docker_image_quickstart_tutorial.md) <a href="https://hub.docker.com/r/ultralytics/yolov5"><img src="https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker" alt="Docker Pulls"></a>

## Project Status

<a href="https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml"><img src="https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg" alt="YOLOv5 CI"></a>

This badge indicates that all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are successfully passing. These CI tests rigorously check the functionality and performance of YOLOv5 across various key aspects: [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py), [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py), and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py). They ensure consistent and reliable operation on macOS, Windows, and Ubuntu, with tests conducted every 24 hours and upon each new commit.
